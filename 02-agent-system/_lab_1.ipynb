{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f4d959",
   "metadata": {},
   "source": [
    "# Introduction to Semantic Kernel Agents\n",
    "\n",
    "Welcome to this workshop on Semantic Kernel (SK) agents! In this notebook, we'll explore how to create, configure, and use agents with the Semantic Kernel framework.\n",
    "\n",
    "## What You'll Learn\n",
    "- What agents are in Semantic Kernel\n",
    "- How to create and configure different types of agents\n",
    "- Basic and advanced interaction patterns with agents\n",
    "- How to integrate plugins and functions with agents\n",
    "\n",
    "Let's start by setting up our environment and understanding the foundational concepts of Semantic Kernel agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f281d",
   "metadata": {},
   "source": [
    "## 1. Introduction to Semantic Kernel Agents\n",
    "\n",
    "### What are agents in Semantic Kernel?\n",
    "\n",
    "In Semantic Kernel, an **agent** is a specialized component that can interact with Large Language Models (LLMs), process conversations, make decisions, and potentially execute code or call functions. Unlike simple prompt-based interactions, agents maintain state, follow instructions, and can engage in multi-turn conversations to accomplish tasks.\n",
    "\n",
    "At their core, agents are designed to:\n",
    "- Process user inputs and generate contextual responses\n",
    "- Maintain conversation history and context\n",
    "- Execute functions when appropriate (function calling)\n",
    "- Work independently or collaborate with other agents\n",
    "\n",
    "\n",
    "### Agent Architecture in Semantic Kernel\n",
    "\n",
    "Key components in the agent architecture:\n",
    "\n",
    "1. **Kernel**: The core orchestration engine that connects agents to AI services and functions\n",
    "2. **AI Service**: The underlying LLM that powers the agent (like Azure OpenAI, OpenAI)\n",
    "3. **Chat History**: Maintains the conversation context over multiple turns\n",
    "4. **Plugins/Functions**: Optional extensions that allow the agent to perform specific tasks\n",
    "\n",
    "### Types of Agents in Semantic Kernel\n",
    "\n",
    "Semantic Kernel primarily offers two types of agents:\n",
    "\n",
    "1. **ChatCompletionAgent**\n",
    "   - Lightweight agent that uses your kernel's chat completion service\n",
    "   - Good for simple conversational tasks\n",
    "   - Manages chat history locally\n",
    "\n",
    "2. **OpenAIAssistantAgent / AzureAssistantAgent**\n",
    "   - Uses OpenAI's Assistant API\n",
    "   - Maintains conversation state remotely as \"threads\"\n",
    "   - Supports advanced features like code interpretation and file searching\n",
    "   - Requires explicit thread management\n",
    "\n",
    "Let's first install the necessary packages to work with Semantic Kernel agents:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff8f44",
   "metadata": {},
   "source": [
    "Now, let's set up our environment by loading environment variables and importing the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d152f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import Semantic Kernel components\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    OpenAIChatCompletion,\n",
    ")\n",
    "from semantic_kernel.contents import ChatHistory, ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Display the environment variables for debugging, from .env file\n",
    "print(\"Environment Variables:\")\n",
    "for key, value in os.environ.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a97966",
   "metadata": {},
   "source": [
    "For this workshop, we'll need to set up our environment variables with either Azure OpenAI or OpenAI credentials. You can create a `.env` file in the same directory as this notebook with the following variables:\n",
    "\n",
    "```\n",
    "AZURE_OPENAI_ENDPOINT='[YOUR_ENDPOINT]'\n",
    "AZURE_OPENAI_API_KEY='[YOUR_API_KEY]'\n",
    "AZURE_OPENAI_MODEL_DEPLOYMENT_NAME='gpt-4o'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32307ce",
   "metadata": {},
   "source": [
    "## 2. Setting Up Your Environment\n",
    "\n",
    "Now that we understand what agents are and have imported the necessary modules, let's begin by creating our first kernel instance and configuring the environment properly.\n",
    "\n",
    "### Creating a Kernel Instance\n",
    "\n",
    "The `Kernel` is the central orchestration component in Semantic Kernel. It manages AI services, plugins, and other resources that agents need to function. Let's now create a helper function that will configure a kernel with the appropriate AI service based on the available credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_kernel_with_service(service_id):\n",
    "    kernel = sk.Kernel()\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=service_id,\n",
    "            deployment_name=os.getenv(\"AZURE_OPENAI_MODEL_DEPLOYMENT_NAME\"),\n",
    "            api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "            endpoint=os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "        )\n",
    "    )\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5885f19",
   "metadata": {},
   "source": [
    "Now let's create our first kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584efa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = create_kernel_with_service(service_id=\"chat-completion\")\n",
    "print(\"Kernel created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dd3dfe",
   "metadata": {},
   "source": [
    "### Understanding Service Configuration\n",
    "\n",
    "When adding an AI service to the kernel, we specified a `service_id`. This ID is important because:\n",
    "\n",
    "1. It allows you to add multiple services to the same kernel\n",
    "2. You can selectively use different services for different agents\n",
    "3. It helps organize and identify your services\n",
    "\n",
    "If you need specific execution settings for your AI service (like temperature, top-p, or function calling behavior), you can retrieve and modify them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44efdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the execution settings for our service\n",
    "settings = kernel.get_prompt_execution_settings_from_service_id(\n",
    "    service_id=\"chat-completion\"\n",
    ")\n",
    "\n",
    "# Configure settings\n",
    "settings.temperature = 0.7\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a19c85",
   "metadata": {},
   "source": [
    "### Exercise: Create Multiple Services in a Kernel\n",
    "\n",
    "In this exercise, try creating a kernel with two different AI services with different configurations. This will be useful when we want to use different services for different agents or functions.\n",
    "\n",
    "Your task:\n",
    "1. Create a new kernel\n",
    "2. Add two services with different service IDs (e.g., \"creative\" and \"precise\")\n",
    "3. Configure the \"creative\" service with higher temperature (e.g., 0.8)\n",
    "4. Configure the \"precise\" service with lower temperature (e.g., 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new kernel for multiple services\n",
    "multi_service_kernel = sk.Kernel()\n",
    "\n",
    "# Add first service - creative with higher temperature\n",
    "multi_service_kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=\"creative\",\n",
    "        deployment_name=os.getenv(\"AZURE_OPENAI_MODEL_DEPLOYMENT_NAME\"),\n",
    "        api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "        endpoint=os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add second service - precise with lower temperature\n",
    "multi_service_kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=\"precise\",\n",
    "        deployment_name=os.getenv(\"AZURE_OPENAI_MODEL_DEPLOYMENT_NAME\"),\n",
    "        api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "        endpoint=os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Configure the settings for each service\n",
    "creative_settings = multi_service_kernel.get_prompt_execution_settings_from_service_id(service_id=\"creative\")\n",
    "creative_settings.temperature = 0.8\n",
    "print(f\"Creative service temperature: {creative_settings.temperature}\")\n",
    "\n",
    "precise_settings = multi_service_kernel.get_prompt_execution_settings_from_service_id(service_id=\"precise\")\n",
    "precise_settings.temperature = 0.2\n",
    "print(f\"Precise service temperature: {precise_settings.temperature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc602c9e",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click to see solution</summary>\n",
    "\n",
    "    ```python\n",
    "# Create a new kernel for multiple services\n",
    "multi_service_kernel = sk.Kernel()\n",
    "\n",
    "# Add first service - creative with higher temperature\n",
    "\n",
    "multi_service_kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=\"creative\",\n",
    "        deployment_name=os.getenv(\"AZURE_OPENAI_MODEL_DEPLOYMENT_NAME\"),\n",
    "        api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "        endpoint=os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add second service - precise with lower temperature\n",
    "multi_service_kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=\"precise\",\n",
    "        deployment_name=os.getenv(\"AZURE_OPENAI_MODEL_DEPLOYMENT_NAME\"),\n",
    "        api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "        endpoint=os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Configure the settings for each service\n",
    "creative_settings = multi_service_kernel.get_prompt_execution_settings_from_service_id(service_id=\"creative\")\n",
    "creative_settings.temperature = 0.8\n",
    "print(f\"Creative service temperature: {creative_settings.temperature}\")\n",
    "\n",
    "precise_settings = multi_service_kernel.get_prompt_execution_settings_from_service_id(service_id=\"precise\")\n",
    "precise_settings.temperature = 0.2\n",
    "print(f\"Precise service temperature: {precise_settings.temperature}\")\n",
    "    ```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa2ca98",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "In this section, we've learned how to:\n",
    "\n",
    "1. **Set up our environment** with necessary imports and credentials\n",
    "2. **Create a kernel** as the foundation for our agents\n",
    "3. **Configure AI services** with specific IDs and settings\n",
    "4. **Manage execution settings** to control how the AI generates responses\n",
    "\n",
    "In the next section, we'll create our first agent using the kernel we've just configured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f8098",
   "metadata": {},
   "source": [
    "## 3. Your First Agent: ChatCompletionAgent\n",
    "\n",
    "Now that we have our kernel and services set up, let's create our first agent. We'll start with the `ChatCompletionAgent`, which is a simple yet powerful agent that leverages the chat completion capabilities of large language models.\n",
    "\n",
    "### Creating a Basic Agent\n",
    "\n",
    "To create a `ChatCompletionAgent`, we need to provide:\n",
    "1. A kernel with a configured chat service\n",
    "2. Instructions that define the agent's behavior\n",
    "3. Optional parameters like a name and execution settings\n",
    "\n",
    "Let's create a simple assistant agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e9b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple assistant agent\n",
    "assistant_agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You are a helpful assistant that provides concise and accurate information. Keep your responses brief but informative.\",\n",
    ")\n",
    "\n",
    "print(f\"Agent '{assistant_agent.name}' created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d54dc8",
   "metadata": {},
   "source": [
    "### Configuring Instructions and Parameters\n",
    "\n",
    "The `instructions` parameter is crucial as it defines how your agent will behave. Think of it as the \"system prompt\" that shapes the agent's personality, capabilities, and limitations. Let's explore some more complex instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_tutor_agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"MathTutor\",\n",
    "    instructions=\"\"\"You are a math tutor specialized in helping students understand mathematical concepts.\n",
    "    \n",
    "    When responding to questions:\n",
    "    1. First explain the underlying concept in simple terms\n",
    "    2. Then walk through the solution step by step\n",
    "    3. Provide a simple example to reinforce the learning\n",
    "    4. Avoid solving problems directly without explanation\n",
    "    \n",
    "    Always be encouraging and patient.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "print(f\"Agent '{math_tutor_agent.name}' created with specialized instructions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829908a6",
   "metadata": {},
   "source": [
    "### Understanding Agent Execution\n",
    "\n",
    "Once an agent is created, it needs a chat history to interact with. The chat history maintains the state of the conversation and provides context for the agent's responses.\n",
    "\n",
    "Here's a simple example of how to execute an agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ef40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat history to maintain conversation state\n",
    "chat_history = ChatHistory()\n",
    "\n",
    "# Add a user message to the chat history\n",
    "chat_history.add_message(\n",
    "    ChatMessageContent(\n",
    "        role=AuthorRole.USER, content=\"Hello! Can you introduce yourself?\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Define a function to execute the agent asynchronously\n",
    "async def get_agent_response(agent, history):\n",
    "    # Get a single response from the agent\n",
    "    response = await agent.get_response(messages=history)\n",
    "    return response\n",
    "\n",
    "\n",
    "# Execute the agent\n",
    "response = await get_agent_response(assistant_agent, chat_history)\n",
    "\n",
    "# Print the agent's response\n",
    "print(f\"Agent: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55322e73",
   "metadata": {},
   "source": [
    "There are actually three main ways to invoke an agent:\n",
    "\n",
    "1. **`get_response()`**: Returns a single response directly as a `ChatMessageContent` object\n",
    "2. **`invoke()`**: Returns an async iterable of `ChatMessageContent` objects\n",
    "3. **`invoke_stream()`**: Streams the response in real-time (useful for long responses)\n",
    "\n",
    "Let's see how `invoke()` works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2a5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new chat history\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_message(\n",
    "    ChatMessageContent(\n",
    "        role=AuthorRole.USER, content=\"What can you tell me about quantum computing?\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define a function to invoke the agent using invoke()\n",
    "async def invoke_agent(agent, history):\n",
    "    responses = []\n",
    "    # Iterate through the responses asynchronously\n",
    "    async for response in agent.invoke(messages=history):\n",
    "        responses.append(response)\n",
    "    return responses\n",
    "\n",
    "\n",
    "# Execute the agent\n",
    "responses = await invoke_agent(assistant_agent, chat_history)\n",
    "\n",
    "# Print the responses\n",
    "for i, response in enumerate(responses):\n",
    "    # Access the message content correctly through the AgentResponseItem\n",
    "    message_text = response.message.content\n",
    "    print(f\"Response {i + 1}: {message_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5cce99",
   "metadata": {},
   "source": [
    "### Exercise: Implement a Simple Question-Answering Agent\n",
    "\n",
    "Now it's your turn to create a custom agent. Implement a question-answering agent that specializes in providing factual information about a specific topic of your choice.\n",
    "\n",
    "Your task:\n",
    "1. Create a new `ChatCompletionAgent` with a descriptive name\n",
    "2. Configure it with detailed instructions that define its area of expertise and how it should respond\n",
    "3. Create a chat history with a relevant question\n",
    "4. Execute the agent and display its response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6efbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here to create and execute a question-answering agent\n",
    "\n",
    "# 1. Create your agent with specialized instructions\n",
    "\n",
    "# 2. Create a chat history with a relevant question\n",
    "\n",
    "# 3. Execute the agent and get its response\n",
    "\n",
    "# 4. Print the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449bcc3d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Create a specialized space expert agent with detailed instructions\n",
    "space_expert_agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"SpaceExpert\",\n",
    "    instructions=\"\"\"You are an expert in astronomy and space exploration.\n",
    "    \n",
    "    When answering questions:\n",
    "    - Provide factual, scientifically accurate information\n",
    "    - Include relevant dates, measurements, and statistics when applicable\n",
    "    - Explain complex concepts in accessible language\n",
    "    - Differentiate between established facts and theoretical or speculative ideas\n",
    "    - When appropriate, mention recent developments or missions\n",
    "    \n",
    "    Focus on being educational and inspiring curiosity about space.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Create a chat history with a specific astronomy question\n",
    "space_chat = ChatHistory()\n",
    "space_chat.add_message(ChatMessageContent(\n",
    "    role=AuthorRole.USER, \n",
    "    content=\"What are exoplanets and how do scientists detect them?\"\n",
    "))\n",
    "\n",
    "# Helper function to get the agent's response\n",
    "async def get_expert_response(agent, history):\n",
    "    response = await agent.get_response(messages=history)\n",
    "    return response\n",
    "\n",
    "# Execute the agent and get its response\n",
    "space_response = await get_expert_response(agent=space_expert_agent, history=space_chat)\n",
    "\n",
    "# Display the agent's response\n",
    "print(f\"SpaceExpert: {space_response.content}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dd014b",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "In this section, we've learned how to:\n",
    "\n",
    "1. **Create a basic `ChatCompletionAgent`** with specific instructions\n",
    "2. **Configure agent instructions** to define specialized behavior\n",
    "3. **Use template parameters** in instructions for dynamic behavior\n",
    "4. **Execute agents** using different invocation methods\n",
    "\n",
    "In the next section, we'll explore more complex interactions with agents, including multi-turn conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7134b776",
   "metadata": {},
   "source": [
    "## 4. Basic Agent Interactions\n",
    "\n",
    "Now that we've created agents, let's explore how to interact with them in a more conversational way. This involves understanding chat history, adding messages, and processing responses over multiple turns.\n",
    "\n",
    "### Chat History Fundamentals\n",
    "\n",
    "The `ChatHistory` class is fundamental to agent interactions. It:\n",
    "- Maintains the chronological sequence of messages in a conversation\n",
    "- Provides context for the agent to generate relevant responses\n",
    "- Allows for multi-turn conversations with memory of previous exchanges\n",
    "\n",
    "Let's create a new chat history and explore its basic functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae802306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new chat history\n",
    "chat = ChatHistory()\n",
    "\n",
    "# Add system message (optional but useful for setting global context)\n",
    "chat.add_message(\n",
    "    ChatMessageContent(\n",
    "        role=AuthorRole.SYSTEM,\n",
    "        content=\"This is a conversation between a user and an AI assistant.\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add user message\n",
    "chat.add_message(\n",
    "    ChatMessageContent(\n",
    "        role=AuthorRole.USER, content=\"Hello, I have some questions about programming.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Print the chat history\n",
    "print(\"Chat history:\")\n",
    "for message in chat.messages:\n",
    "    print(f\"{message.role.name}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eecb2f2",
   "metadata": {},
   "source": [
    "### Adding User Messages\n",
    "\n",
    "There are a few ways to add user messages to a chat history:\n",
    "\n",
    "1. Using the generic `add_message()` method as shown above\n",
    "2. Using the convenience method `add_user_message()`\n",
    "\n",
    "Let's use the second approach to continue our conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10361a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a user message using the convenience method\n",
    "chat.add_user_message(\"What's the difference between Python and JavaScript?\")\n",
    "\n",
    "# Print the updated chat history\n",
    "print(\"Updated chat history:\")\n",
    "for message in chat.messages:\n",
    "    print(f\"{message.role.name}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d64b164",
   "metadata": {},
   "source": [
    "### Processing Agent Responses\n",
    "\n",
    "When an agent generates a response, it's important to add it back to the chat history to maintain the conversation flow. Let's see how to do this in a multi-turn conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to handle a multi-turn conversation\n",
    "async def have_conversation(agent, chat_history, user_messages):\n",
    "    \"\"\"Have a multi-turn conversation with an agent.\n",
    "\n",
    "    Args:\n",
    "        agent: The ChatCompletionAgent to converse with\n",
    "        chat_history: The ChatHistory to use for the conversation\n",
    "        user_messages: A list of strings representing user messages\n",
    "    \"\"\"\n",
    "\n",
    "    for i, message in enumerate(user_messages):\n",
    "        # Add the user message to chat history\n",
    "        chat_history.add_user_message(message)\n",
    "\n",
    "        print(f\"User: {message}\")\n",
    "\n",
    "        # Get the agent's response\n",
    "        response = await agent.get_response(messages=chat_history)\n",
    "\n",
    "        # Add the agent's response to chat history\n",
    "        chat_history.add_message(response.content)\n",
    "        print(f\"Agent: {response.content}\")\n",
    "    \n",
    "    print(chat_history)\n",
    "\n",
    "\n",
    "# Create a fresh chat history\n",
    "programming_chat = ChatHistory()\n",
    "\n",
    "# List of user messages for a multi-turn conversation\n",
    "user_messages = [\n",
    "    \"What is Python used for?\",\n",
    "    \"How does it compare to Java?\",\n",
    "    \"What would you recommend for a beginner to learn first?\",\n",
    "]\n",
    "\n",
    "# Create a programming tutor agent\n",
    "programming_tutor = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"ProgrammingTutor\",\n",
    "    instructions=\"You are an experienced programming tutor who explains concepts clearly and concisely. Make your answers very concise.\",\n",
    ")\n",
    "\n",
    "# Have a conversation\n",
    "await have_conversation(programming_tutor, programming_chat, user_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb57eb",
   "metadata": {},
   "source": [
    "## 5. Function Calling and Plugins\n",
    "\n",
    "One of the most powerful features of Semantic Kernel agents is their ability to use plugins and call functions. This enables agents to go beyond just generating text and actually perform actions, retrieve information, and integrate with external systems.\n",
    "\n",
    "### What are Plugins in Semantic Kernel?\n",
    "\n",
    "In Semantic Kernel, a **plugin** is a collection of related functions that can be registered with the kernel and made available to agents. Plugins can:\n",
    "- Retrieve information from databases or APIs\n",
    "- Perform calculations or data transformations\n",
    "- Execute system operations\n",
    "- Interact with external services\n",
    "\n",
    "Plugins contain one or more **functions**, which can be:\n",
    "1. **Native Functions**: Written in code (Python) that execute when called\n",
    "2. **Semantic Functions**: Defined by prompts that are sent to the LLM when called\n",
    "\n",
    "Let's create a simple plugin with native functions to demonstrate how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c38641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.functions import kernel_function, KernelFunction\n",
    "from typing import Annotated\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Define a simple plugin class with useful functions\n",
    "class UtilityPlugin:\n",
    "    \"\"\"A plugin with utility functions for time, math, and other operations.\"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Get the current date and time.\")\n",
    "    def get_current_time(self) -> str:\n",
    "        \"\"\"Get the current date and time in ISO format.\"\"\"\n",
    "        return datetime.datetime.now().isoformat()\n",
    "\n",
    "    @kernel_function(description=\"Calculate the square root of a number.\")\n",
    "    def square_root(\n",
    "        self, number: Annotated[float, \"The number to calculate the square root of.\"]\n",
    "    ) -> str:\n",
    "        \"\"\"Calculate the square root of a given number.\"\"\"\n",
    "        return str(round(number**0.5, 4))\n",
    "\n",
    "    @kernel_function(description=\"Convert temperatures between Celsius and Fahrenheit.\")\n",
    "    def convert_temperature(\n",
    "        self,\n",
    "        temp: Annotated[float, \"The temperature to convert.\"],\n",
    "        unit: Annotated[str, \"The source unit ('C' or 'F')\"],\n",
    "    ) -> str:\n",
    "        \"\"\"Convert temperatures between Celsius and Fahrenheit.\"\"\"\n",
    "        if unit.upper() == \"C\":\n",
    "            # Convert from Celsius to Fahrenheit\n",
    "            result = (temp * 9 / 5) + 32\n",
    "            return f\"{temp}째C is equal to {round(result, 2)}째F\"\n",
    "        elif unit.upper() == \"F\":\n",
    "            # Convert from Fahrenheit to Celsius\n",
    "            result = (temp - 32) * 5 / 9\n",
    "            return f\"{temp}째F is equal to {round(result, 2)}째C\"\n",
    "        else:\n",
    "            return f\"Invalid unit: {unit}. Please use 'C' for Celsius or 'F' for Fahrenheit.\"\n",
    "\n",
    "\n",
    "# Create a new utility plugin instance\n",
    "utility_plugin = UtilityPlugin()\n",
    "\n",
    "# Add the plugin to our kernel\n",
    "kernel.add_plugin(utility_plugin, plugin_name=\"Utility\")\n",
    "\n",
    "print(\n",
    "    \"Utility plugin registered with functions:\",\n",
    "    [f for f in kernel.get_plugin(\"Utility\").functions],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f7cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.function_choice_behavior import (\n",
    "    FunctionChoiceBehavior,\n",
    ")\n",
    "\n",
    "# First, get the execution settings for our service\n",
    "settings = kernel.get_prompt_execution_settings_from_service_id(\n",
    "    service_id=\"chat-completion\"\n",
    ")\n",
    "\n",
    "# Configure automatic function calling\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "# Create an agent with access to our functions\n",
    "math_assistant = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"MathAssistant\",\n",
    "    instructions=\"\"\"You are a helpful assistant that can perform mathematical calculations and utility operations.\n",
    "    Use the available functions when appropriate to provide accurate answers.\n",
    "    For calculations, always use the provided functions rather than calculating yourself.\n",
    "    Make your answers clear and concise.\n",
    "    \"\"\",\n",
    "    arguments=KernelArguments(\n",
    "        settings=settings\n",
    "    ),  # Pass the settings with auto function calling\n",
    ")\n",
    "\n",
    "print(f\"Created agent '{math_assistant.name}' with auto function calling enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5437650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents.function_call_content import FunctionCallContent\n",
    "from semantic_kernel.contents.function_result_content import FunctionResultContent\n",
    "\n",
    "\n",
    "# Create a function that shows function calls and results\n",
    "async def demonstrate_function_calling(agent, history, question):\n",
    "    print(f\"\\nUser: {question}\")\n",
    "    history.add_user_message(question)\n",
    "\n",
    "    # Use invoke to see the full process including function calls\n",
    "    function_calls = []\n",
    "    function_results = []\n",
    "\n",
    "    async for response in agent.invoke(messages=history):\n",
    "        for item in response.items:\n",
    "            if isinstance(item, FunctionCallContent):\n",
    "                function_call = item\n",
    "                function_calls.append(function_call)\n",
    "                print(f\"\\n{80 * '-'}\")\n",
    "                print(f\"Function call: {function_call.function_name}\")\n",
    "                print(f\"Arguments: {function_call.arguments}\")\n",
    "            elif isinstance(item, FunctionResultContent):\n",
    "                function_result = item\n",
    "                function_results.append(function_result)\n",
    "                print(f\"Function result: {function_result.result}\")\n",
    "                print(80 * \"-\")\n",
    "            else:\n",
    "                # This is the final response\n",
    "                history.add_assistant_message(item.text)\n",
    "                print(f\"\\nAgent: {item.text}\")\n",
    "\n",
    "    return {\n",
    "        \"function_calls\": function_calls,\n",
    "        \"function_results\": function_results\n",
    "    }\n",
    "\n",
    "\n",
    "# Test with different questions\n",
    "questions = [\n",
    "    \"What's the square root of 144?\",\n",
    "    \"Can you convert 25 degrees Celsius to Fahrenheit?\",\n",
    "    \"What's the current date and time?\",\n",
    "]\n",
    "\n",
    "# Test each question\n",
    "for question in questions:\n",
    "    # Create a chat history\n",
    "    function_chat = ChatHistory()\n",
    "    await demonstrate_function_calling(math_assistant, function_chat, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0868effc",
   "metadata": {},
   "source": [
    "### Exercise: Create Your Own Agent with a Plugin\n",
    "\n",
    "Go to the **single agent application** and finish it using the knowledge and skills you got from this lab.  \n",
    "\n",
    "Inside the `kernel_setup.py` file, you will find some instructions on what to do. Once you have finished the functions,  \n",
    "you can run the application with:\n",
    "\n",
    "```bash\n",
    "streamlit run sample_apps\\single_agent\\app.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
