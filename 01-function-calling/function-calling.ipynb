{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edaa8231",
   "metadata": {},
   "source": [
    "<a id='functioncalling'></a>\n",
    "### üß™ Test OpenAI function calling\n",
    "\n",
    "The following code was reused from the [Azure OpenAI documentation](https://learn.microsoft.com/azure/ai-services/openai/how-to/function-calling?tabs=non-streaming%2Cpython). The `UUID` will be used to search for the end-to-end transaction in Application insights.\n",
    "\n",
    "- Note: run ```pip install openai``` in a terminal before executing this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54302088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "from openai import AzureOpenAI\n",
    "import uuid\n",
    "\n",
    "prompt = \"What's the weather like in London and its big sister cities?\"\n",
    "\n",
    "UUID = str(uuid.uuid4())\n",
    "print(\n",
    "    f\"Request-Id: {UUID} - use this ID to trace the requests in Azure Application Insights.\"\n",
    ")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=apim_resource_gateway_url,\n",
    "    api_key=apim_subscription_key,\n",
    "    api_version=openai_api_version,\n",
    ")\n",
    "\n",
    "\n",
    "# Example function hard coded to return the same weather\n",
    "# the local function calls the API\n",
    "def get_current_weather(location, unit):\n",
    "    request = {\"location\": location, \"unit\": unit}\n",
    "    url = apim_resource_gateway_url + \"/weather\"\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        headers={\"api-key\": apim_subscription_key, \"Request-Id\": UUID},\n",
    "        json=request,\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n",
    "\n",
    "# Step 1: send the conversation and available functions to the model\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location, using the local temperature measuring unit.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The temperature measuring unit, e.g. celsius for London or fahrenheit for US cities\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\", \"unit\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "print(\n",
    "    \"‚ñ∂Ô∏è Step 1: start a completion to identify the appropriate functions to invoke based on the prompt\\n\",\n",
    "    prompt,\n",
    ")\n",
    "response = client.chat.completions.create(\n",
    "    model=openai_deployment_name,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    extra_headers={\"Request-Id\": UUID},\n",
    ")\n",
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "if tool_calls:\n",
    "    # Step 2: call the function\n",
    "    # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "    available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "    }  # only one function in this example, but you can have multiple\n",
    "    messages.append(response_message)  # extend conversation with assistant's reply\n",
    "    # send the info for each function call and function response to the model\n",
    "    print(\"‚ñ∂Ô∏è Step 2: call the functions\")\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        function_response = function_to_call(\n",
    "            location=function_args.get(\"location\"),\n",
    "            unit=function_args.get(\"unit\"),\n",
    "        )\n",
    "        print(function_response)\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "    print(\n",
    "        \"‚ñ∂Ô∏è Step 3: finish with a completion to anwser the user prompt using the function response\"\n",
    "    )\n",
    "    second_response = client.chat.completions.create(\n",
    "        model=openai_deployment_name,\n",
    "        messages=messages,\n",
    "        extra_headers={\"Request-Id\": UUID},\n",
    "    )  # get a new response from the model where it can see the function response\n",
    "    print(second_response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
